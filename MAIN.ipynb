{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êImports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Relevant Papers** <br />\n",
    "https://arxiv.org/pdf/1407.5675.pdf <br />\n",
    "https://arxiv.org/pdf/1701.08784.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "# Possibly Redundant\n",
    "from scipy import ndimage, misc\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import data, img_as_float\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 0: Read the data (tar.gz file) & Explore it\n",
    "**Read**\n",
    "\n",
    "As a first step, we unzipped the tar.gz file into a .dat file using 7-zip. \n",
    "Then, we convert the .dat file into a string and then into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".strip() --> remove spaces on the sides\n",
    "\n",
    ".split() --> separate values by spaces (otherwise we'd get a single conlumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .dat file into string (list comprehension)\n",
    "datContent = [i.strip().split() for i in open(\"tth_semihad.dat\").readlines()]\n",
    "\n",
    "# Convert list into DataFrame\n",
    "mydata = pd.DataFrame(datContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore**\n",
    "\n",
    "**Physics**\n",
    "\n",
    "Jonas: \"The file was produced from a simulation of pp->tt~H where the top decays hadronically\n",
    "and the anti-top decays leptonically. <br /> I selected events with exactly 1 fat jet with R=1.5.\"\n",
    "\n",
    "\n",
    "**Notes**\n",
    "- The rows represent events (of 1 fat jet each, R = 1.5) \n",
    "- The first column represents the number of constituents of the jet  \n",
    "- The following columns represent the coordinates of the constituents, Œ∑, œÜ, pT, cycling in that order. <br />(e.g. columns 1, 2, 3 are Œ∑, œÜ, pT for the 1st constituent, columns 4, 5, 6 are Œ∑, œÜ, pT for the 2nd constituent etc.)\n",
    "\n",
    "<br />\n",
    "\n",
    "- -infinity < Œ∑ < infinity \n",
    "- -œÄ < œÜ < œÄ\n",
    "- pT[GeV] > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the data\n",
    "# mydata = mydata.rename(columns={0: 'Const'})\n",
    "# display(mydata.head())\n",
    "\n",
    "# # Print statements\n",
    "# events = mydata.shape[0]\n",
    "# print('There are {} rows (events).'.format(events))\n",
    "# print('The maximum number of constituents in an event is {}.'.format((mydata.shape[1] - 1) // 3))\n",
    "\n",
    "## Display data types\n",
    "#print('\\nData Types: \\n', mydata.dtypes)\n",
    "\n",
    "## Descriptive statistics on data\n",
    "#mydata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define helper function that\n",
    "- drops the constituents column \n",
    "- converts NaN to 0\n",
    "- converts values to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(event1):\n",
    "    '''\n",
    "    -Extracts no. of constituents\n",
    "    -Drops constituents column\n",
    "    -Replaces NaN values with 0\n",
    "    -Converts all values to floats\n",
    "    \n",
    "    Input: Series (event) to be processed\n",
    "    Output: Processed Series, constituents Series \n",
    "    '''\n",
    "    \n",
    "    # Create series copy\n",
    "    event = event1.copy(deep=True)\n",
    "    \n",
    "    # Drop constituents from series\n",
    "    event = event.drop(event.index[0])\n",
    "    \n",
    "    # Replace NaN with 0\n",
    "    event = event.fillna(0)\n",
    "\n",
    "    # Convert values to floats\n",
    "    event = event.astype(float)\n",
    "    \n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 2: Create Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that turns an event into an image\n",
    "- Bins coordinates (Œ∑, œÜ, pT)\n",
    "- Creates image using np.histogram2d(). pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(event1, R=1.5, pixels=60):\n",
    "    \n",
    "    '''\n",
    "    Creates an image of single event, or multiple events (input can be either Series or DataFrame). If DataFrame, then average image is created.  \n",
    "    \n",
    "    Input: series\n",
    "    Output: array\n",
    "    \n",
    "    table: if df=True, then display the image as a DataFrame as well\n",
    "    '''\n",
    "    \n",
    "    # Create copy of df so that it's not accidentally modified\n",
    "    event = event1.copy(deep=True)\n",
    "    \n",
    "    # If input is Series (single event) then turn into DataFrame. This makes it so that single events are processed correctly\n",
    "    if isinstance(event, pd.Series):\n",
    "        event = pd.DataFrame(event).T\n",
    "\n",
    "    # Initiate bin lists\n",
    "    bin_h = []\n",
    "    bin_f = []\n",
    "    bin_p = []\n",
    "\n",
    "    # Define max number of constituents \n",
    "    max_const = event.shape[1] // 3\n",
    "\n",
    "    # For all rows\n",
    "    #for i in range(event.shape[0]):             \n",
    "\n",
    "    # For all constituents (I tested it using only meaningful constituents from first column and the code was slower)\n",
    "    for i in range(max_const):\n",
    "        # Add constituent's coordinates to bin lists\n",
    "        bin_h.append(list(event.iloc[0][::3])[i])\n",
    "        bin_f.append(list(event.iloc[0][1::3])[i])\n",
    "        bin_p.append(list(event.iloc[0][2::3])[i])\n",
    "\n",
    "# Tried not doing it for pT=0 constituents. Was less efficient\n",
    "#     i = 0\n",
    "#     while i < max_const and list(event.iloc[0][2::3])[i] != 0.:\n",
    "#         bin_h.append(list(event.iloc[0][::3])[i])\n",
    "#         bin_f.append(list(event.iloc[0][1::3])[i])\n",
    "#         bin_p.append(list(event.iloc[0][2::3])[i])\n",
    "#         i += 1\n",
    "\n",
    "    \n",
    "\n",
    "    # Turn lists into Series\n",
    "    bin_h = pd.Series(bin_h)\n",
    "    bin_f = pd.Series(bin_f)\n",
    "    bin_p = pd.Series(bin_p)\n",
    "\n",
    "   # Define no. of bins\n",
    "    bin_count = np.linspace(-R, R, pixels + 1)\n",
    "\n",
    "    # Create bins from -R to R (using bins vector)\n",
    "    bins = np.histogram2d(bin_h, bin_f, bins=bin_count, weights=bin_p)[0] # x and y are switch because when the bins were turned into a Series the shape[0] and shape[1] were switched\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    image = bins\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that \n",
    "- Reads directly from the file\n",
    "- Returns an average image\n",
    "\n",
    "**NOTE:** event_no list implementation for multiple images is not working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_image(pixels=60, R=1.5, event_no=12178, display=False):\n",
    "    '''\n",
    "    pixels: Image Resolution, int.\n",
    "    event_no: # of events for which images be created. If int, then single image (faster) If list, then multiple images (slower)\n",
    "    '''\n",
    "\n",
    "    image = np.zeros((pixels, pixels))                  # Define initial image\n",
    "\n",
    "    \n",
    "    # Display Images\n",
    "    if display == True and type(event_no) == list:\n",
    "        \n",
    "        images = []                                         # List containing the output images\n",
    "        a = 0                                               # Define Counter\n",
    "        \n",
    "        with open(\"tth_semihad.dat\") as infile:\n",
    "            for line in infile:\n",
    "\n",
    "                event=line.strip().split()\n",
    "                event = pd.Series(event)                         # Turn into Series\n",
    "                event = preprocess(event)                        # Preprocess\n",
    "                #event = normalise_p(event)                       # Normalise pT's\n",
    "                max123 = extract_max123(event)                   # Extract maxima\n",
    "                event = center(event, max123)                    # Center \n",
    "                #event = rotate(event, max123)                   # Rotate \n",
    "                #event = flip(event, max123)                     # Flip \n",
    "                event = create_image(event, pixels=pixels, R=R)  # Create image\n",
    "                image += event                                   # Add event image to average image\n",
    "                #image = np.log(image)                            # Log transform pT's for smaller numbers\n",
    "                #image /= np.amax(image)                          # Normalise final image between 0 and 1\n",
    "                event = max123 = None                            # Delete from memory\n",
    "\n",
    "                a += 1\n",
    "                if a in event_no:\n",
    "                    sns.heatmap(image, robust=True)\n",
    "                    plt.show()\n",
    "                    sns.heatmap(image)\n",
    "                    plt.show()\n",
    "                    break\n",
    "                    \n",
    "    \n",
    "    # Return single image\n",
    "    elif type(event_no) == int:\n",
    "        \n",
    "        with open(\"tth_semihad.dat\") as infile:\n",
    "            for line in infile:\n",
    "\n",
    "                event=line.strip().split()\n",
    "                event = pd.Series(event)                         # Turn into Series\n",
    "                event = preprocess(event)                        # Preprocess\n",
    "                #event = normalise_p(event)                       # Normalise pT's\n",
    "                max123 = extract_max123(event)                   # Extract maxima\n",
    "                event = center(event, max123)                    # Center \n",
    "                #event = rotate(event, max123)                   # Rotate \n",
    "                #event = flip(event, max123)                     # Flip \n",
    "                event = create_image(event, pixels=pixels, R=R)  # Create image\n",
    "                image += event                                   # Add event image to average image\n",
    "                #image = np.log(image)                            # Log transform pT's for smaller numbers\n",
    "                #image /= np.amax(image)                          # Normalise final image between 0 and 1\n",
    "                event = max123 = None                            # Delete from memory\n",
    "        \n",
    "            return image\n",
    "        \n",
    "    # Return multiple images\n",
    "    ##### Not working properly\n",
    "    elif type(event_no) == list:\n",
    "        \n",
    "        images = []                                         # List containing the output images\n",
    "        a = 0                                               # Define Counter\n",
    "        \n",
    "        with open(\"tth_semihad.dat\") as infile:\n",
    "            for line in infile:\n",
    "\n",
    "                event=line.strip().split()\n",
    "                event = pd.Series(event)                         # Turn into Series\n",
    "                event = preprocess(event)                        # Preprocess\n",
    "                #event = normalise_p(event)                       # Normalise pT's\n",
    "                max123 = extract_max123(event)                   # Extract maxima\n",
    "                event = center(event, max123)                    # Center \n",
    "                #event = rotate(event, max123)                   # Rotate \n",
    "                #event = flip(event, max123)                     # Flip \n",
    "                event = create_image(event, pixels=pixels, R=R)  # Create image\n",
    "                image += event                                   # Add event image to average image\n",
    "                #image = np.log(image)                            # Log transform pT's for smaller numbers\n",
    "                #image /= np.amax(image)                          # Normalise final image between 0 and 1\n",
    "                event = max123 = None                            # Delete from memory\n",
    "\n",
    "                a += 1\n",
    "                if a in event_no:\n",
    "                    images.append(image)\n",
    "    \n",
    "        return images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise/Log pT (Still doesn't work without robust)\n",
    "Note: the log transformation can simply be done on the final ndarray and it's much more efficient (and doesnt require a function)\n",
    "\n",
    "Also tried normalising the whole image using image /= np.amax(image) and results were even worse. **Though this might be a good form to feed it to the algorithm in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_p(event1):\n",
    "    # Define p indices to be used later\n",
    "    p_indices = event1[2::3].index\n",
    "\n",
    "    # Create copy of event\n",
    "    event = event1.copy(deep=True)\n",
    "\n",
    "    # Calculate sum (only for normalisation)\n",
    "    total_p = 0\n",
    "    for p_index in p_indices:\n",
    "        total_p += event.iloc[2::3][p_index]\n",
    "    \n",
    "    # For all p in the event\n",
    "    for p_index in p_indices:             \n",
    "\n",
    "        # Define Useful Quantities\n",
    "        num_index = event.name                   \n",
    "        \n",
    "        # p Normalisation\n",
    "        event.iloc[2::3][p_index] /= total_p                                         # Normalise\n",
    "        #event.iloc[2::3][p_index] = math.log(event.iloc[2::3][p_index], 10)         # Log Transform\n",
    "\n",
    "        \n",
    "#     if output == 'event':\n",
    "#         return event\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 3: Extract Maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that \n",
    "\n",
    "returns 3 vectors, one for each pT and its Œ∑, œÜ. (For the three maximum pT's)\n",
    "\n",
    "- **1st vector**: 1st maximum pT and its Œ∑, œÜ\n",
    "- **2nd vector**: 2nd maximum pT and its Œ∑, œÜ\n",
    "- **3rd vector**: 3rd maximum pT and its Œ∑, œÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_max123(event1):\n",
    "\n",
    "    '''\n",
    "    Input: event (row). \n",
    "    e.g. mydata_prep.iloc[0]\n",
    "\n",
    "    Output[0]: [Series of 1st max p, œÜ, Œ∑]\n",
    "    Output[1]: [Series of 2nd max p, œÜ, Œ∑]\n",
    "    Output[2]: [Series of 3rd max p, œÜ, Œ∑]\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Create event copy\n",
    "    event = event1.copy(deep=True)\n",
    "\n",
    "    # Separate Œ∑, œÜ, pT\n",
    "    hdata = event[::3]\n",
    "    fdata = event[1::3]\n",
    "    pdata1 = event[2::3]\n",
    "\n",
    "\n",
    "\n",
    "    # 1. Extract index of maximum pT\n",
    "    maxid1 = pdata1.idxmax()\n",
    "    maxlist1 = []\n",
    "\n",
    "    # 2. Extract max Œ∑, œÜ, pT for event\n",
    "    if pdata1.max() != 0:                                                                     # Brief explanation of if statement below)\n",
    "        maxlist1.append([event.iloc[maxid1-1], event.iloc[maxid1-2], event.iloc[maxid1-3]])   # From event, add to list the max pT and its Œ∑, œÜ\n",
    "    else:\n",
    "        maxlist1.append([0., event.iloc[maxid1-2], event.iloc[maxid1-3]])                    # If max pT is 0, then add it as 0 and not the first value\n",
    "\n",
    "    # 3. Create & Display dataframe of max pT, Œ∑, œÜ\n",
    "    row_max1 = pd.Series(data=maxlist1[0], index=['pT', 'œÜ', 'Œ∑'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 0. Set Max pT to 0 to find next Max pT\n",
    "    pdata2 = pdata1.copy(deep=True)\n",
    "    pdata2.loc[maxid1] = 0\n",
    "\n",
    "    # 1. Extract index of maximum pT\n",
    "    maxid2 = pdata2.idxmax()\n",
    "    maxlist2 = []\n",
    "\n",
    "    # 2. Extract max Œ∑, œÜ, pT for event\n",
    "    if pdata2.max() != 0:                                                                     # Brief explanation of if statement below)\n",
    "        maxlist2.append([event.iloc[maxid2-1], event.iloc[maxid2-2], event.iloc[maxid2-3]])   # From event, add to list the max pT and its Œ∑, œÜ\n",
    "    else:\n",
    "        maxlist2.append([0., event.iloc[maxid2-2], event.iloc[maxid2-3]])                    # If max pT is 0, then add it as 0 and not the first value\n",
    "\n",
    "    # 3. Create & Display dataframe of max pT, Œ∑, œÜ\n",
    "    row_max2 = pd.Series(data=maxlist2[0], index=['pT', 'œÜ', 'Œ∑'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 0. Set Max pT to 0 to find next Max pT\n",
    "    pdata3 = pdata2.copy(deep=True)\n",
    "    pdata3.loc[maxid2] = 0\n",
    "\n",
    "    # 1. Extract index of maximum pT\n",
    "    maxid3 = pdata3.idxmax()\n",
    "    maxlist3 = []\n",
    "\n",
    "    # 2. Extract max Œ∑, œÜ, pT for event\n",
    "    if pdata3.max() != 0:                                                                     # Brief explanation of if statement below)\n",
    "        maxlist3.append([event.iloc[maxid3-1], event.iloc[maxid3-2], event.iloc[maxid3-3]])   # From event, add to list the max pT and its Œ∑, œÜ\n",
    "    else:\n",
    "        maxlist3.append([0., event.iloc[maxid3-2], event.iloc[maxid3-3]])                    # If max pT is 0, then add it as 0 and not the first value\n",
    "\n",
    "    # 3. Create & Display dataframe of max pT, Œ∑, œÜ\n",
    "    row_max3 = pd.Series(data=maxlist3[0], index=['pT', 'œÜ', 'Œ∑'])\n",
    "\n",
    "\n",
    "\n",
    "    return row_max1, row_max2, row_max3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why the if statement?** (note to self) <br />\n",
    "Because if maximum pT is 0 in the pdata vector, it picks the ID of the first pT by default as the max (because they're all 0). <br />\n",
    "Then, it goes to the non-zero'd event vector and adds its non-zero pT as the max, when the value of that max should clearly have been 0.\n",
    "\n",
    "So the if statement fixes this: <br />\n",
    "- If max pT != 0, then add it as normal.\n",
    "- If max pT = 0, then add '0' as its value instead. (with the coordinates of the first pT, which is incorrect, but this doesn't matter since pT = 0 are not taken into account in the image) <br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 4: Centre Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row, we centre a new coordinate system so that the highest pT constituent's coordinates are (œÜ', Œ∑') = (0, 0). <br />\n",
    "This corresponds to rotating and boosting along the beam direction to center the jet.\n",
    "\n",
    "**œÜ Tranformation**<br />\n",
    "For the œÜ transformation, we subtract the œÜ (of the max pT) from all œÜ's in that row. <br />\n",
    "If the values exceed [-œÄ, œÄ], we add 2œÄ to the final result (if it's <-œÄ) or subtract 2œÄ from the final result (if it's >œÄ). This makes sure that no values exceed the original œÜ interval. <br />\n",
    "This has the effect of making the œÜ (corresponding to the max pT for that row) equal to 0 in each row, and shifting the other œÜ's by that same angle, while maintaining a range of 2œÄ. <br />\n",
    "\n",
    "**Œ∑ Transformation**<br />\n",
    "How does Œ∑ transform? We need a Lorentz Transformation. \n",
    "\n",
    "**Paper** (E) <br />\n",
    "Histograms binned in\n",
    "either the angular separation of events or the rapidity separation of events can\n",
    "be contributed to by events whose centre of mass frames are boosted by arbitrary velocities with respect to the rest frame of the detector, the lab frame.\n",
    "The resulting histograms are undistorted by these centre of mass frame boosts\n",
    "parallel to the beam axis, as the dependent variable is invariant with respect\n",
    "to this sub‚Äìclass of Lorentz boosts.\n",
    "\n",
    "**Paper** (F): make code cell below markdown to display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<img src=\"h1.png\" width=\"500\"> <img src=\"h2.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(event1, max123, output='event', R=1.5, pixels=60):\n",
    "    \n",
    "    '''\n",
    "    Centers image around (œÜ', Œ∑') = (0, 0). Both transformations are linear (so far). \n",
    "    \n",
    "    event1: the event (row) to be transformed\n",
    "    max123: list of 3 dataframes of max pT, Œ∑, œÜ. Obtained using the extract_max123() function\n",
    "    output: 'event' to return a Series of the transformed event1. 'image' to return a transformed dataframe representing an image \n",
    "    '''\n",
    "    \n",
    "    # Define Œ∑, œÜ indices to be used later\n",
    "    h_indices = event1[::3].index\n",
    "    f_indices = event1[1::3].index\n",
    "\n",
    "    # Create copy of event\n",
    "    event = event1.copy(deep=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # For all Œ∑, œÜ in the event\n",
    "    for h_index, f_index in zip(h_indices, f_indices):             \n",
    "\n",
    "        # Define Useful Quantities\n",
    "        num_index = event.name                   # index of event, so that we can find its corresponding œÜ in the max123[0] dataframe of max pT's and œÜ, Œ∑'s\n",
    "        maxh = max123[0].loc['Œ∑']                # Œ∑ of max1 pT value\n",
    "        maxf = max123[0].loc['œÜ']                # œÜ of max1 pT value\n",
    "        f = event.iloc[1::3][f_index]            # œÜ original value\n",
    "        \n",
    "        # Œ∑ Transformation\n",
    "        event.iloc[::3][h_index] -= maxh         # Subtract max Œ∑ from current Œ∑\n",
    "        \n",
    "        # œÜ Transformation (Note: the if statements take periodicity into account, making sure that range does not exceed 2œÄ)\n",
    "        if (f - maxf) < -np.pi:\n",
    "            event.iloc[1::3][f_index] = f + 2*np.pi - maxf\n",
    "\n",
    "        elif (f - maxf) > np.pi:\n",
    "            event.iloc[1::3][f_index] = f - 2*np.pi - maxf\n",
    "\n",
    "        else: \n",
    "            event.iloc[1::3][f_index] -= maxf     # Subtract max œÜ from current œÜ\n",
    "\n",
    "\n",
    "    if output == 'event':\n",
    "        return event\n",
    "    \n",
    "    \n",
    "    elif output == 'image':\n",
    "        # Initiate bin lists\n",
    "        bin_h = []\n",
    "        bin_f = []\n",
    "        bin_p = []\n",
    "\n",
    "        # Define max number of constituents \n",
    "        max_const = event.shape[0] // 3\n",
    "        # For all constituents\n",
    "        for i in range(max_const):\n",
    "            # Add constituent's Œ∑, œÜ, p to bins\n",
    "            bin_h.append(list(event.iloc[::3])[i])\n",
    "            bin_f.append(list(event.iloc[1::3])[i])\n",
    "            bin_p.append(list(event.iloc[2::3])[i])\n",
    "\n",
    "        # Turn lists into Series\n",
    "        bin_h = pd.Series(bin_h)\n",
    "        bin_f = pd.Series(bin_f)\n",
    "        bin_p = pd.Series(bin_p)\n",
    "\n",
    "        # Define no. of bins\n",
    "        bin_count = np.linspace(-R, R, pixels + 1)\n",
    "\n",
    "        # Create bins from -R to R and convert to DataFrame\n",
    "        bins = np.histogram2d(bin_h, bin_f, bins=bin_count, weights=bin_p)[0] # x and y are switch because when the bins were turned into a Series the shape[0] and shape[1] were switched\n",
    "        image = bins\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = average_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5590.0495624343675"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johng\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.628743432377169"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(np.log(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 5: Rotate Image\n",
    "\n",
    "Rotate all constituents around (œÜ‚Äô,Œ∑‚Äô)=0 such that the constituent with the 2nd highest pT is at 12 o‚Äôclock, i.e. at  (œÜ‚Äô,Œ∑‚Äô)=(0,e) with e > 0.\n",
    "\n",
    "**Paper (C)** <br />\n",
    "\"Rotation: Rotation is performed to remove the stochastic nature of the decay\n",
    "angle relative to the Œ∑ ‚àí œÜ coordinate system. This alignment can be done very\n",
    "generally, by determining the principle axis [48] of the original image and rotating the imagine around the jet-energy centroid such that the principle axis\n",
    "is always vertical.\"\n",
    "\n",
    "#### Resources\n",
    "https://stackoverflow.com/questions/53854066/pythonhow-to-rotate-an-image-so-that-a-feature-becomes-vertical\n",
    "\n",
    "https://alyssaq.github.io/2015/computing-the-axes-or-orientation-of-a-blob/\n",
    "\n",
    "https://pythontic.com/image-processing/pillow/rotate\n",
    "\n",
    "https://www.askpython.com/python/examples/rotate-an-image-by-an-angle-in-python\n",
    "\n",
    "https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that\n",
    "\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 6: Flip Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip all the constituents such that the constituents with the 3rd highest pT is on the right-half plane, i.e. at (œÜ‚Äô,Œ∑‚Äô)=(f,e) with f > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that\n",
    "\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
