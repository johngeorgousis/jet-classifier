{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êJonas Questions\n",
    "- \n",
    "- \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êImports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "from processing_functions import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define helper function that\n",
    "- drops the constituents column \n",
    "- converts NaN to 0\n",
    "- converts values to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 2: Create Image & Average Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ Create Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that takes an event as input and returns an image\n",
    "- Bins coordinates (Œ∑, œÜ, pT)\n",
    "- Creates image using np.histogram2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_image(event, R=1.5, pixels=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ Create Average Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that reads events directly from a file and returns an average image\n",
    "\n",
    "\n",
    "**NOTE:** event_no list implementation for multiple images is not working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average_image(pixels=60, R=1.5, event_no=12178, display=False):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example (Image Progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average_image(pixels = 100, event_no=[25, 300, 3000, 12000], display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 3: Extract Maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define 3 Helper Functions that \n",
    "\n",
    "Return one vector each with the highest pT and its Œ∑, œÜ. (For the three maximum pT's)\n",
    "\n",
    "- **1st function**: 1st maximum pT and its Œ∑, œÜ\n",
    "- **2nd function**: 2nd maximum pT and its Œ∑, œÜ\n",
    "- **3rd function**: 3rd maximum pT and its Œ∑, œÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_max1(event)\n",
    "#find_max2(event)\n",
    "#find_max3(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 4: Centre Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row, we centre a new coordinate system so that the highest pT constituent's coordinates are (œÜ', Œ∑') = (0, 0). <br />\n",
    "This corresponds to rotating and boosting along the beam direction to center the jet.\n",
    "\n",
    "**œÜ Tranformation**<br />\n",
    "For the œÜ transformation, we subtract the œÜ (of the max pT) from all œÜ's in that row. <br />\n",
    "If the values exceed [-œÄ, œÄ], we add 2œÄ to the final result (if it's <-œÄ) or subtract 2œÄ from the final result (if it's >œÄ). This makes sure that no values exceed the original œÜ interval. <br />\n",
    "This has the effect of making the œÜ (corresponding to the max pT for that row) equal to 0 in each row, and shifting the other œÜ's by that same angle, while maintaining a range of 2œÄ. <br />\n",
    "\n",
    "**Œ∑ Transformation**<br />\n",
    "How does Œ∑ transform? We need a Lorentz Transformation. \n",
    "\n",
    "**Paper** (E) <br />\n",
    "Histograms binned in\n",
    "either the angular separation of events or the rapidity separation of events can\n",
    "be contributed to by events whose centre of mass frames are boosted by arbitrary velocities with respect to the rest frame of the detector, the lab frame.\n",
    "The resulting histograms are undistorted by these centre of mass frame boosts\n",
    "parallel to the beam axis, as the dependent variable is invariant with respect\n",
    "to this sub‚Äìclass of Lorentz boosts.\n",
    "\n",
    "**Paper** (F): make code cell below markdown to display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<img src=\"h1.png\" width=\"500\"> <img src=\"h2.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function <br />\n",
    "Centers image around (œÜ', Œ∑') = (0, 0). Both transformations are linear (so far). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#center(event, max123, output='event', R=1.5, pixels=60):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 5: Rotate Image\n",
    "\n",
    "Rotate all constituents around (œÜ‚Äô,Œ∑‚Äô)=0 such that the constituent with the 2nd highest pT is at 12 o‚Äôclock, i.e. at  (œÜ‚Äô,Œ∑‚Äô)=(0,e) with e > 0.\n",
    "\n",
    "**Paper (C)** <br />\n",
    "\"Rotation: Rotation is performed to remove the stochastic nature of the decay\n",
    "angle relative to the Œ∑ ‚àí œÜ coordinate system.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that\n",
    "\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotate(event, max2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êStep 6: Flip Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip all the constituents such that the constituents with the 3rd highest pT is on the right-half plane, i.e. at (œÜ‚Äô,Œ∑‚Äô)=(f,e) with f > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Define Helper Function that\n",
    "\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip(event, max3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average_image(pixels=100, event_no=[1, 10, 100, 1000, 5000, 12000], display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_image(pixels=100, event_no=[1, 10, 50, 100, 1000, 3000, 8000, 17000], display=True, file='wjets.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_image(pixels=100, event_no=[1, 10, 50, 100, 1000, 5000, 12000], display=True, file='tth_semihad.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background12000 = average_image(pixels=100, event_no=12000, file='wjets.dat')\n",
    "# background17000 = average_image(pixels=100, event_no=17000, file='wjets.dat')\n",
    "# signal12000 = average_image(pixels=100, event_no=12000, file='tth_semihad.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(background12000, robust=True)\n",
    "# plt.title('Background Image with 12000 Events')\n",
    "# plt.xlabel('œÜ\\'')\n",
    "# plt.ylabel('Œ∑\\'')\n",
    "# plt.show()\n",
    "\n",
    "# sns.heatmap(signal12000, robust=True)\n",
    "# plt.title('Signal Image with 12000 Events')\n",
    "# plt.xlabel('œÜ\\'')\n",
    "# plt.ylabel('Œ∑\\'')\n",
    "# plt.show()\n",
    "\n",
    "# sns.heatmap(background17000, robust=True)\n",
    "# plt.title('Background Image with 17000 Events')\n",
    "# plt.xlabel('œÜ\\'')\n",
    "# plt.ylabel('Œ∑\\'')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠ê Building Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Import Data\n",
    "\n",
    "1. Import signal/background data (~7min 30sec)\n",
    "2. Concatenate & Shuffle signal/background data\n",
    "3. Convert to tf.data.Dataset object\n",
    "\n",
    "\n",
    "**Save Dataset**\n",
    "\n",
    "The easiest way is to pickle it using to_pickle:\n",
    "\n",
    "`df.to_pickle(file_name)`, where to save it, usually as a .pkl\n",
    "\n",
    "Then you can load it back using:\n",
    "\n",
    "`df = pd.read_pickle(file_name)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 7.44 mins :(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Import, Preprocess, Create Dataset\n",
    "sdata = create_dataset('data_signal.dat')\n",
    "bdata = create_dataset('data_background.dat')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: {:.2f} mins :(\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Datasets\n",
    "pd.DataFrame(sdata).to_pickle('sdata')\n",
    "pd.DataFrame(sdata).to_pickle('bdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat and Suffle\n",
    "data = np.concatenate((sdata, bdata), axis=0)\n",
    "data = sklearn.utils.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Examples and Labels\n",
    "data= pd.DataFrame(data, columns=['examples', 'labels'])\n",
    "examples= data['examples']\n",
    "labels = data['labels']\n",
    "\n",
    "# Turn into ndarray to convert to tf.data.Dataset object\n",
    "examples = np.array(examples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert to tf.data.Dataset object\n",
    "data = tf.data.Dataset.from_tensor_slices(([examples], [labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \n",
    "valid_data = \n",
    "test_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Convert .dat files into DataFrame objects\n",
    "# sdata = pd.DataFrame([i.strip().split() for i in open(\"tth_semihad.dat\").readlines()])\n",
    "# bdata = pd.DataFrame([i.strip().split() for i in open(\"wjets.dat\").readlines()])\n",
    "\n",
    "# # Label data\n",
    "# sdata['label'] = np.ones(sdata.shape[0])\n",
    "# bdata['label'] = np.zeros(bdata.shape[0])\n",
    "\n",
    "# # Concatenate & Shuffle\n",
    "# data = pd.concat([sdata, bdata])\n",
    "# data = shuffle(data)\n",
    "\n",
    "# # Extract labels & drop\n",
    "# labels = np.array(data['label'])\n",
    "# data = data.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Build the Model\n",
    "\n",
    "Look up ConvNet TF Tutorial and make a Conv2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 451,138\n",
      "Trainable params: 451,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pixels = 40\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "           tf.keras.layers.Flatten(input_shape=(pixels, pixels)),\n",
    "           tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "           tf.keras.layers.Dropout(0.2),\n",
    "           tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "           tf.keras.layers.Dropout(0.2),\n",
    "           tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "           tf.keras.layers.Dropout(0.2),\n",
    "           tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# model2 = tf.keras.Sequential([\n",
    "#           tf.keras.layers.Flatten(input_shape=(pixels, pixels)),\n",
    "#           tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#           tf.keras.layers.MaxPooling2D(),\n",
    "#           tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#           tf.keras.layers.MaxPooling2D(),\n",
    "#           tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#           tf.keras.layers.MaxPooling2D(),\n",
    "#           tf.keras.layers.Flatten(),\n",
    "#           tf.keras.layers.Dense(128, activation='relu'),\n",
    "#           tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "# ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Compile the Model\n",
    "- **Optimizer** -- Determines how the model is updated based on the data it sees and its loss function\n",
    "- **Loss Function** -- Measures how accurate the model is during training\n",
    "- **Metrics** -- Monitors the training and testing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "\n",
    "# for images, labels in train_data.take(1):\n",
    "#       for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         sns.heatmap(images[i].numpy().astype(\"uint8\"))\n",
    "#         #plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(i)\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Batches\n",
    "\n",
    "- Dataset.prefetch() overlaps data preprocessing and model execution while training.\n",
    "\n",
    "- Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "\n",
    "Theory guide: https://www.tensorflow.org/guide/data_performance#prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_batches = train_data.cache().shuffle(num_training_examples//4).batch(batch_size).prefetch(1)\n",
    "\n",
    "valid_batches = validation_set.cache().batch(batch_size).prefetch(1)  # or prefetch(buffer_size=tf.data.experimental.AUTOTUNE) \n",
    "\n",
    "test_batches = test_set.cache().batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_batches = train_data.cache().shuffle(num_training_examples//4).batch(batch_size).prefetch(1)\n",
    "\n",
    "valid_batches = validation_set.cache().batch(batch_size).prefetch(1)  # or prefetch(buffer_size=tf.data.experimental.AUTOTUNE) \n",
    "\n",
    "test_batches = test_set.cache().batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Early Stopping**: <br /> \n",
    "Stop training when there is no improvement in the validation loss for 5 consecutive epochs or when metric gain is less than 0.001\n",
    "\n",
    "**Save Best**: <br />\n",
    "Saves the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta = 0.001)\n",
    "# save_best = tf.keras.callbacks.ModelCheckpoint('./best_model.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit model to training data\n",
    "# EPOCHS = 10\n",
    "# history = model.fit(train_data, # tuple (events_train, labels_train)\n",
    "#           epochs=EPOCHS,\n",
    "#           callbacks= [early_stopping, save_best],\n",
    "#           validation_data=valid_data, # tuple (events_val, labels_val)\n",
    "#           verbose=2\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model-Complexity Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_accuracy = history.history['accuracy']\n",
    "# validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# training_loss = history.history['loss']\n",
    "# validation_loss = history.history['val_loss']\n",
    "\n",
    "# epochs_range=range(len(training_accuracy))\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, training_loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs_range = range(EPOCHS)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = my_model.evaluate(test_data, verbose=2)\n",
    "\n",
    "# print('\\nLoss on the TEST Set: {:,.3f}'.format(loss))\n",
    "# print('Accuracy on the TEST Set: {:.3%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event, label in test_data.take(1):\n",
    "#     ps = model.predict(event)\n",
    "#     images = event.numpy().squeeze()\n",
    "#     labels = label.numpy()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,15))\n",
    "\n",
    "# for n in range(30):\n",
    "#     plt.subplot(6,5,n+1)\n",
    "#     plt.imshow(images[n], cmap = plt.cm.binary)\n",
    "#     color = 'green' if np.argmax(ps[n]) == labels[n] else 'red'\n",
    "#     plt.title(class_names[np.argmax(ps[n])], color=color)\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event, label in training_batches.take(1):\n",
    "#     ps = model.predict(event)\n",
    "#     first_image = event.numpy().squeeze()[0]\n",
    "  \n",
    "  \n",
    "# fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "# ax1.imshow(first_image, cmap = plt.cm.binary)\n",
    "# ax1.axis('off')\n",
    "# ax2.barh(np.arange(10), ps[0])\n",
    "# ax2.set_aspect(0.1)\n",
    "# ax2.set_yticks(np.arange(10))\n",
    "# ax2.set_yticklabels(np.arange(10))\n",
    "# ax2.set_title('Class Probability')\n",
    "# ax2.set_xlim(0, 1.1)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Build Confusion Matrix \n",
    "\n",
    "Guide:\n",
    "https://kapernikov.com/tutorial-image-classification-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
